"use client";

import { useEffect, useRef, useState } from "react";

import Image from "next/image";
import Peer from "peerjs";
import { generateUniqueId } from "@/utils/generateUniqueId";

const DollyZoomCamera = () => {
  const myVideoRef = useRef<HTMLVideoElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<Blob[]>([]);

  const [peerInstance, setPeerInstance] = useState<Peer | null>(null);
  const [myUniqueId, setMyUniqueId] = useState<string>("");
  const [viewerId, setViewerId] = useState<string>("");
  const [callStatus, setCallStatus] = useState<string>("");
  const [connectionStatus, setConnectionStatus] =
    useState<string>("ì—°ê²° ì¤‘...");
  const [isStreaming, setIsStreaming] = useState(false);
  const [debugLogs, setDebugLogs] = useState<string[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [recordingTimer, setRecordingTimer] = useState<number | null>(null);
  const [recordingDuration, setRecordingDuration] = useState<number>(0);
  const MAX_RECORDING_DURATION = 60; // ìµœëŒ€ ë…¹í™” ì‹œê°„ (ì´ˆ)
  const [zoomLevel, setZoomLevel] = useState<number>(2);
  const touchStartYRef = useRef<number | null>(null);
  const isDraggingRef = useRef<boolean>(false);

  // í•„ìš”í•œ ì¶”ê°€ ref ì„ ì–¸
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const canvasStreamRef = useRef<MediaStream | null>(null);
  const animationFrameRef = useRef<number | null>(null);

  // ë¡œê·¸ë¥¼ í™”ë©´ì— í‘œì‹œí•˜ê¸° ìœ„í•œ í•¨ìˆ˜
  const addDebugLog = (message: string) => {
    setDebugLogs((prev) => [
      ...prev.slice(-9),
      `${new Date().toLocaleTimeString()}: ${message}`,
    ]);
  };

  // ì•ˆì „í•˜ê²Œ getUserMediaë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
  const safeGetUserMedia = async () => {
    try {
      // ë¨¼ì € ê¶Œí•œ ìƒíƒœ í™•ì¸
      const permissions = await navigator.permissions.query({
        name: "camera" as PermissionName,
      });

      if (permissions.state === "denied") {
        return Promise.reject(new Error("Camera permission denied"));
      }

      // ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ì²˜ë¦¬
      if (!navigator.mediaDevices) {
        // ì¼ë¶€ ì˜¤ë˜ëœ ë¸Œë¼ìš°ì €ì—ì„œëŠ” mediaDevicesê°€ ì—†ì„ ìˆ˜ ìˆìŒ
        return Promise.reject(new Error("mediaDevices not supported"));
      }

      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: "environment",
          zoom: 2, // ì´ˆê¸° ì¤Œ ë ˆë²¨ì„ 2ë¡œ ì„¤ì •
        } as MediaTrackConstraints,
        audio: true,
      });

      // ì¤Œ ê¸°ëŠ¥ ì§€ì› í™•ì¸ ë° ì´ˆê¸° ì„¤ì •
      const videoTrack = stream.getVideoTracks()[0];
      if (videoTrack && "getCapabilities" in videoTrack) {
        const capabilities =
          videoTrack.getCapabilities() as MediaTrackCapabilities;
        if (capabilities.zoom) {
          addDebugLog(
            `Zoom supported: ${capabilities.zoom.min} - ${capabilities.zoom.max}`
          );
          // ì´ˆê¸° ì¤Œ ë ˆë²¨ ì„¤ì •
          await videoTrack.applyConstraints({
            advanced: [{ zoom: zoomLevel } as MediaTrackConstraintSet],
          });
        }
      }

      return stream;
    } catch (err) {
      console.error("Media access error:", err);

      if (err instanceof Error) {
        switch (err.name) {
          case "NotAllowedError":
            break;
          case "NotFoundError":
            // ì˜¤ë””ì˜¤ë§Œ ì‹œë„
            try {
              const audioOnlyStream = await navigator.mediaDevices.getUserMedia(
                {
                  video: false,
                  audio: true,
                }
              );
              return audioOnlyStream;
            } catch (audioErr) {}
            break;
          case "NotReadableError":
            break;
          case "OverconstrainedError":
            // ë” ë‚®ì€ í•´ìƒë„ë¡œ ì¬ì‹œë„
            try {
              const lowResStream = await navigator.mediaDevices.getUserMedia({
                video: true, // ì œì•½ ì¡°ê±´ ì—†ì´ ì‹œë„
                audio: true,
              });
              return lowResStream;
            } catch (lowResErr) {}
            break;
          default:
            break;
        }
      } else {
      }
      throw err;
    }
  };

  // í™˜ê²½ì— ë”°ë¼ ë‹¤ë¥¸ PeerJS ì„œë²„ ì„¤ì • ì‚¬ìš©
  const getPeerConfig = () => {
    // ê°œë°œ í™˜ê²½
    if (process.env.NODE_ENV === "development") {
      return {
        host: "localhost",
        port: 9000,
        path: "/myapp",
        secure: false,
      };
    }

    // í”„ë¡œë•ì…˜ í™˜ê²½ - ë²„ì…€ ë°°í¬ìš© ì„¤ì •
    const isSecure =
      typeof window !== "undefined" && window.location.protocol === "https:";

    // RailwayëŠ” ì¼ë°˜ì ìœ¼ë¡œ í¬íŠ¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì§€ ì•ŠìŒ
    return {
      host: process.env.NEXT_PUBLIC_API_URL || window.location.hostname,
      // Railwayì—ì„œëŠ” í¬íŠ¸ë¥¼ ìƒëµí•˜ê³  ê¸°ë³¸ HTTPS í¬íŠ¸(443) ì‚¬ìš©
      // port: 8080,
      path: "/myapp",
      secure: isSecure,
      debug: 3,
      config: {
        iceServers: [
          { urls: "stun:stun.l.google.com:19302" },
          { urls: "stun:global.stun.twilio.com:3478" },
          // TURN ì„œë²„ ì¶”ê°€ (WebRTC ì—°ê²°ì´ NAT/ë°©í™”ë²½ ë’¤ì—ì„œ ì‹¤íŒ¨í•  ê²½ìš° í•„ìš”)
          {
            urls: "turn:numb.viagenie.ca",
            username: "webrtc@live.com",
            credential: "muazkh",
          },
        ],
      },
    };
  };

  // ìƒˆë¡œìš´ í•¨ìˆ˜: URLì—ì„œ viewerId íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
  const getViewerIdFromUrl = () => {
    if (typeof window !== "undefined") {
      const urlParams = new URLSearchParams(window.location.search);
      const id = urlParams.get("id");
      return id || "dolly-zoom-viewer"; // ê¸°ë³¸ê°’ ì œê³µ
    }
    return "dolly-zoom-viewer"; // ì„œë²„ ì‚¬ì´ë“œì—ì„œëŠ” ê¸°ë³¸ê°’ ë°˜í™˜
  };

  const startRecording = async (stream: MediaStream) => {
    recordedChunksRef.current = [];
    setRecordingDuration(0); // ë…¹í™” ì‹œê°„ ì´ˆê¸°í™”

    try {
      // ë…¹í™” ì „ í˜„ì¬ ì¤Œ ë ˆë²¨ ì ìš©
      const videoTrack = stream.getVideoTracks()[0];
      if (videoTrack && "getCapabilities" in videoTrack) {
        const capabilities =
          videoTrack.getCapabilities() as MediaTrackCapabilities;
        if (capabilities.zoom) {
          await videoTrack.applyConstraints({
            advanced: [{ zoom: zoomLevel } as MediaTrackConstraintSet],
          });
          addDebugLog(`ë…¹í™” ì‹œì‘ ì „ ì¤Œ ë ˆë²¨ ì„¤ì •: ${zoomLevel}`);
        }
      }

      // ì§€ì›í•˜ëŠ” MIME íƒ€ì… í™•ì¸
      const mimeTypes = [
        "video/webm;codecs=vp8", // vp8ì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ì‘ì€ íŒŒì¼ í¬ê¸°
        "video/webm",
        "video/mp4",
        "video/webm;codecs=vp9",
      ];

      let mimeType = "";
      for (const type of mimeTypes) {
        if (MediaRecorder.isTypeSupported(type)) {
          mimeType = type;
          addDebugLog(`ì§€ì›í•˜ëŠ” MIME íƒ€ì…: ${type}`);
          break;
        }
      }

      if (!mimeType) {
        addDebugLog("ì§€ì›í•˜ëŠ” ë¹„ë””ì˜¤ MIME íƒ€ì…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        return;
      }

      try {
        const mediaRecorder = new MediaRecorder(stream, {
          mimeType: mimeType,
          videoBitsPerSecond: 800000, // 800 Kbpsë¡œ ë” ë‚®ê²Œ ì œí•œ (íŒŒì¼ í¬ê¸° ê°ì†Œ)
        });

        // 5ì´ˆë§ˆë‹¤ ë°ì´í„° ì²­í¬ ìƒì„±
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            recordedChunksRef.current.push(event.data);
            addDebugLog(
              `ë…¹í™” ì²­í¬ í¬ê¸°: ${(event.data.size / 1024 / 1024).toFixed(2)}MB`
            );
          }
        };

        mediaRecorder.start(5000); // 5ì´ˆë§ˆë‹¤ ì²­í¬ ìƒì„±
        mediaRecorderRef.current = mediaRecorder;
        addDebugLog("ë…¹í™”ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ë¹„íŠ¸ë ˆì´íŠ¸: 800Kbps)");

        // 1ë¶„ íƒ€ì´ë¨¸ ì„¤ì •
        const timer = window.setInterval(() => {
          setRecordingDuration((prev) => {
            const newDuration = prev + 1;

            // ìµœëŒ€ ë…¹í™” ì‹œê°„ ë„ë‹¬ ì‹œ ìë™ ì¢…ë£Œ
            if (newDuration >= MAX_RECORDING_DURATION) {
              addDebugLog("ìµœëŒ€ ë…¹í™” ì‹œê°„(1ë¶„) ë„ë‹¬, ìë™ ì¢…ë£Œ");
              clearInterval(timer);
              handleCut(); // ë…¹í™” ì¢…ë£Œ í•¨ìˆ˜ í˜¸ì¶œ
            }

            return newDuration;
          });
        }, 1000);

        setRecordingTimer(timer);
      } catch (err) {
        addDebugLog(`MediaRecorder ìƒì„± ì‹¤íŒ¨: ${err}`);
      }
    } catch (err) {
      addDebugLog(`ë…¹í™” ì‹œì‘ ì „ ì¤Œ ì„¤ì • ì‹¤íŒ¨: ${err}`);
    }
  };

  const stopRecordingAndSave = async () => {
    return new Promise<string>((resolve, reject) => {
      if (!mediaRecorderRef.current) {
        reject(new Error("MediaRecorderë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."));
        return;
      }

      // íƒ€ì´ë¨¸ ì •ë¦¬
      if (recordingTimer) {
        clearInterval(recordingTimer);
        setRecordingTimer(null);
      }

      addDebugLog("ë…¹í™” ì¤‘ì§€ ì¤‘...");
      mediaRecorderRef.current.onstop = async () => {
        try {
          addDebugLog("ë…¹í™” ì¤‘ì§€ë¨, Blob ìƒì„± ì¤‘...");
          const blob = new Blob(recordedChunksRef.current, {
            type: mediaRecorderRef.current?.mimeType || "video/webm",
          });
          const sizeMB = blob.size / 1024 / 1024;
          addDebugLog(`Blob ìƒì„±ë¨ (í¬ê¸°: ${sizeMB.toFixed(2)}MB)`);

          // íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í¬ë©´ ì••ì¶• ì‹œë„
          let uploadBlob = blob;
          if (sizeMB > 10) {
            // Cloudinary ë¬´ë£Œ ê³„ì • ì œí•œ
            addDebugLog(`íŒŒì¼ í¬ê¸°ê°€ í½ë‹ˆë‹¤. ì••ì¶• ì‹œë„ ì¤‘...`);
            try {
              // ë¹„ë””ì˜¤ ì••ì¶• ë¡œì§ (ê°„ë‹¨í•œ í•´ìƒë„ ì¶•ì†Œ)
              const compressedBlob = await compressVideo(blob);
              const compressedSizeMB = compressedBlob.size / 1024 / 1024;
              addDebugLog(`ì••ì¶• í›„ í¬ê¸°: ${compressedSizeMB.toFixed(2)}MB`);
              uploadBlob = compressedBlob;
            } catch (compressErr) {
              addDebugLog(`ì••ì¶• ì‹¤íŒ¨: ${compressErr}. ì›ë³¸ ì‚¬ìš©`);
            }
          }

          // Cloudinary ì§ì ‘ ì—…ë¡œë“œ (ì„œë²„ ìš°íšŒ)
          addDebugLog("Cloudinaryì— ì§ì ‘ ì—…ë¡œë“œ ì‹œë„...");
          const videoUrl = await uploadToCloudinary(uploadBlob);
          addDebugLog("Cloudinary ì—…ë¡œë“œ ì™„ë£Œ, URL ìˆ˜ì‹ ë¨");
          resolve(videoUrl);
        } catch (error) {
          addDebugLog(`ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${error}`);
          reject(error);
        }
      };

      try {
        mediaRecorderRef.current.stop();
      } catch (error) {
        addDebugLog(`MediaRecorder.stop() í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: ${error}`);
        reject(error);
      }
    });
  };

  // ìº”ë²„ìŠ¤ ì´ˆê¸°í™” ë° ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ í•¨ìˆ˜
  const setupCanvas = async (videoStream: MediaStream) => {
    if (!canvasRef.current || !myVideoRef.current) return null;

    const canvas = canvasRef.current;
    const ctx = canvas.getContext("2d");
    if (!ctx) return null;

    // ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì • (ë¹„ë””ì˜¤ì™€ ë™ì¼í•˜ê²Œ)
    const videoTrack = videoStream.getVideoTracks()[0];
    const settings = videoTrack.getSettings();

    // ë¹„ë””ì˜¤ íŠ¸ë™ì˜ ì‹¤ì œ í•´ìƒë„ ì‚¬ìš©
    const width = settings.width || 1280;
    const height = settings.height || 720;

    canvas.width = width;
    canvas.height = height;

    // ë¹„ë””ì˜¤ ìš”ì†Œì— ì›ë³¸ ìŠ¤íŠ¸ë¦¼ ì—°ê²°
    myVideoRef.current.srcObject = videoStream;

    // ìº”ë²„ìŠ¤ì— ë¹„ë””ì˜¤ ê·¸ë¦¬ê¸° í•¨ìˆ˜
    const drawVideoWithZoom = () => {
      if (!ctx || !myVideoRef.current) return;

      // ìº”ë²„ìŠ¤ ì§€ìš°ê¸°
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // ì¤Œ ê³„ì‚° (ì¤‘ì•™ì—ì„œ í™•ëŒ€)
      const scaleFactor = zoomLevel;
      const scaledWidth = canvas.width / scaleFactor;
      const scaledHeight = canvas.height / scaleFactor;
      const centerX = (canvas.width - scaledWidth) / 2;
      const centerY = (canvas.height - scaledHeight) / 2;

      // ë¹„ë””ì˜¤ë¥¼ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸° (ì¤Œ ì ìš©)
      ctx.drawImage(
        myVideoRef.current,
        centerX,
        centerY,
        scaledWidth,
        scaledHeight,
        0,
        0,
        canvas.width,
        canvas.height
      );

      // ë‹¤ìŒ í”„ë ˆì„ ìš”ì²­
      animationFrameRef.current = requestAnimationFrame(drawVideoWithZoom);
    };

    // ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘
    drawVideoWithZoom();

    // ìº”ë²„ìŠ¤ì—ì„œ ìŠ¤íŠ¸ë¦¼ ìƒì„±
    try {
      const canvasStream = canvas.captureStream(30); // 30fps

      // ì˜¤ë””ì˜¤ íŠ¸ë™ ì¶”ê°€ (ì›ë³¸ ìŠ¤íŠ¸ë¦¼ì—ì„œ)
      const audioTracks = videoStream.getAudioTracks();
      audioTracks.forEach((track) => {
        canvasStream.addTrack(track);
      });

      canvasStreamRef.current = canvasStream;
      addDebugLog("ìº”ë²„ìŠ¤ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì„±ê³µ");

      return canvasStream;
    } catch (err) {
      addDebugLog(`ìº”ë²„ìŠ¤ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì‹¤íŒ¨: ${err}`);
      return null;
    }
  };

  // ê¸°ì¡´ handleCall í•¨ìˆ˜ ìˆ˜ì •
  const handleCall = () => {
    addDebugLog("handleCall ì‹œì‘");

    if (!peerInstance) {
      addDebugLog("peerInstanceê°€ ì—†ìŒ");
      setCallStatus(
        "PeerJS ì¸ìŠ¤í„´ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
      );
      return;
    }

    setCallStatus("ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ìš”ì²­ ì¤‘...");

    safeGetUserMedia()
      .then(async (stream) => {
        addDebugLog("ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ íšë“ ì„±ê³µ");

        // ìº”ë²„ìŠ¤ ì„¤ì • ë° ì¤Œ íš¨ê³¼ê°€ ì ìš©ëœ ìŠ¤íŠ¸ë¦¼ ìƒì„±
        const canvasStream = await setupCanvas(stream);

        if (!canvasStream) {
          addDebugLog("ìº”ë²„ìŠ¤ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì‹¤íŒ¨, ì›ë³¸ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©");

          if (myVideoRef.current) {
            myVideoRef.current.srcObject = stream;
          }

          // ì›ë³¸ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì§„í–‰
          proceedWithCall(stream);
        } else {
          addDebugLog("ìº”ë²„ìŠ¤ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì„±ê³µ, ì¤Œ íš¨ê³¼ ì ìš©ë¨");
          proceedWithCall(canvasStream);
        }
      })
      .catch((err) => {
        addDebugLog(`í†µí™” ì‹¤íŒ¨: ${err.toString()}`);
        setCallStatus(`í†µí™” ì‹¤íŒ¨: ${err.toString()}`);
        setIsStreaming(false);
      });
  };

  // í†µí™” ì§„í–‰ í•¨ìˆ˜ (ìŠ¤íŠ¸ë¦¼ ë¶„ë¦¬)
  const proceedWithCall = (stream: MediaStream) => {
    if (!peerInstance) return;

    const call = peerInstance.call(viewerId, stream);
    addDebugLog("í”¼ì–´ í˜¸ì¶œ ì‹œë„: " + viewerId);

    if (!call) {
      addDebugLog("í†µí™” ì—°ê²° ì‹¤íŒ¨");
      setCallStatus("í†µí™” ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìƒëŒ€ë°© IDë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.");
      return;
    }

    setIsStreaming(true);
    setCallStatus("ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ë¨");
    addDebugLog("ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ trueë¡œ ì„¤ì •");

    startRecording(stream);
    addDebugLog("ë…¹í™” ì‹œì‘ë¨");

    call.on("stream", (userVideoStream) => {
      addDebugLog("ìƒëŒ€ë°© ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹  ì„±ê³µ");
      setCallStatus("ìƒëŒ€ë°© ìŠ¤íŠ¸ë¦¼ ì—°ê²°ë¨");
    });

    call.on("error", (err) => {
      addDebugLog(`í†µí™” ì˜¤ë¥˜: ${err.toString()}`);
      setCallStatus(`í†µí™” ì˜¤ë¥˜: ${err.toString()}`);
      setIsStreaming(false);
    });

    call.on("close", () => {
      addDebugLog("í†µí™” ì¢…ë£Œë¨");
      setCallStatus("í†µí™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
      setIsStreaming(false);
    });
  };

  const handleCut = async () => {
    try {
      addDebugLog("ë…¹í™” ì¢…ë£Œ ì‹œë„ ì¤‘...");
      setIsProcessing(true); // ì²˜ë¦¬ ì‹œì‘

      if (!mediaRecorderRef.current) {
        addDebugLog("MediaRecorderê°€ ì—†ìŠµë‹ˆë‹¤.");
        setCallStatus("MediaRecorderê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
        return;
      }

      const videoUrl = await stopRecordingAndSave();
      addDebugLog("ë…¹í™” íŒŒì¼ ì €ì¥ ì™„ë£Œ: " + videoUrl);

      if (peerInstance) {
        addDebugLog("ë…¹í™” ì˜ìƒ URL ì „ì†¡ ì‹œë„");
        const conn = peerInstance.connect(viewerId);
        conn.on("open", () => {
          conn.send({
            type: "recorded-video",
            url: videoUrl,
          });
          addDebugLog("ë…¹í™” ì˜ìƒ URL ì „ì†¡ ì™„ë£Œ");
        });
      }

      setIsStreaming(false);
      addDebugLog("ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ");
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : String(error);
      addDebugLog(`ë…¹í™” ì¢…ë£Œ ì˜¤ë¥˜: ${errorMessage}`);
      setCallStatus(`ë…¹í™” ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: ${errorMessage}`);
    } finally {
      setIsProcessing(false); // ì²˜ë¦¬ ì™„ë£Œ
    }
  };

  // ë” ê°„ë‹¨í•œ ë¹„ë””ì˜¤ ì••ì¶• í•¨ìˆ˜ (ì˜¤ë””ì˜¤ ì—†ìŒ)
  const compressVideo = async (videoBlob: Blob): Promise<Blob> => {
    // ì´ë¯¸ í¬ê¸°ê°€ ì‘ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if (videoBlob.size < 10 * 1024 * 1024) {
      return videoBlob;
    }

    addDebugLog("ê°„ë‹¨í•œ ì••ì¶• ë°©ì‹ ì‚¬ìš© ì¤‘...");

    // ë” ë‚®ì€ ë¹„íŠ¸ë ˆì´íŠ¸ë¡œ MediaRecorder ì„¤ì •
    try {
      // ë¹„ë””ì˜¤ë¥¼ ë‹¤ì‹œ ë…¹í™”í•˜ëŠ” ëŒ€ì‹  Cloudinary ë³€í™˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©
      return videoBlob;
    } catch (err) {
      addDebugLog(`ì••ì¶• ì‹¤íŒ¨: ${err}`);
      return videoBlob;
    }
  };

  // Cloudinary ì—…ë¡œë“œ í•¨ìˆ˜ ìˆ˜ì •
  const uploadToCloudinary = async (videoBlob: Blob) => {
    try {
      addDebugLog("Cloudinaryì— ì§ì ‘ ì—…ë¡œë“œ ì‹œë„...");
      const cloudName =
        process.env.NEXT_PUBLIC_CLOUDINARY_CLOUD_NAME || "your_cloud_name";
      const uploadPreset =
        process.env.NEXT_PUBLIC_CLOUDINARY_UPLOAD_PRESET || "your_preset";

      const formData = new FormData();
      formData.append("file", videoBlob);
      formData.append("upload_preset", uploadPreset);
      formData.append("resource_type", "video");

      // ê¸°ë³¸ ìµœì í™” ì˜µì…˜ë§Œ ì‚¬ìš©
      formData.append("quality", "auto:low");

      // eager ë° angle íŒŒë¼ë¯¸í„° ì œê±° (unsigned ì—…ë¡œë“œì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€)

      const response = await fetch(
        `https://api.cloudinary.com/v1_1/${cloudName}/video/upload`,
        {
          method: "POST",
          body: formData,
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(
          `Cloudinary ì—…ë¡œë“œ ì‹¤íŒ¨ (${response.status}): ${errorText}`
        );
      }

      const data = await response.json();

      // ì›ë³¸ URLì— íšŒì „ ë³€í™˜ íŒŒë¼ë¯¸í„° ì¶”ê°€
      // í˜•ì‹: https://res.cloudinary.com/cloud_name/video/upload/a_-90/video_id
      const originalUrl = data.secure_url;
      const transformedUrl = originalUrl.replace(
        "/upload/",
        "/upload/a_-90,q_auto:low/"
      );

      addDebugLog(`ë³€í™˜ëœ URL: ${transformedUrl}`);

      return transformedUrl;
    } catch (error) {
      addDebugLog(`Cloudinary ì—…ë¡œë“œ ì˜¤ë¥˜: ${error}`);
      throw error;
    }
  };

  // PeerJS ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œ ì„¤ì • ì‚¬ìš©
  useEffect(() => {
    if (myUniqueId) {
      let peer: Peer;
      if (typeof window !== "undefined") {
        const peerConfig = getPeerConfig();

        // ë” ìì„¸í•œ ë””ë²„ê¹… ì •ë³´
        const wsUrl = `${peerConfig.secure ? "wss" : "ws"}://${
          peerConfig.host
        }${peerConfig.port ? `:${peerConfig.port}` : ""}${peerConfig.path}`;

        setConnectionStatus("PeerJS ì„œë²„ì— ì—°ê²° ì¤‘...");

        // ë””ë²„ê¹…ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´
        console.log("PeerJS ì„¤ì •:", peerConfig);
        console.log("í˜„ì¬ URL:", window.location.href);
        console.log(
          "WebSocket URL:",
          `${peerConfig.secure ? "wss" : "ws"}://${peerConfig.host}:${
            peerConfig.port
          }${peerConfig.path}`
        );

        peer = new Peer(myUniqueId, peerConfig);

        // ì—°ê²° ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì¶”ê°€
        peer.on("open", (id) => {
          setConnectionStatus("PeerJS ì„œë²„ì— ì—°ê²°ë¨");
        });

        peer.on("error", (err) => {
          console.error("PeerJS ì˜¤ë¥˜:", err);
          setConnectionStatus(`ì—°ê²° ì˜¤ë¥˜: ${err.type}`);

          // ì—°ê²° ì¬ì‹œë„ ë¡œì§
          if (
            err.type === "network" ||
            err.type === "server-error" ||
            err.type === "socket-error"
          ) {
            setConnectionStatus("5ì´ˆ í›„ ì¬ì—°ê²° ì‹œë„...");
            setTimeout(() => {
              setConnectionStatus("ì¬ì—°ê²° ì‹œë„ ì¤‘...");
              peer.reconnect();
            }, 5000);
          }
        });

        setPeerInstance(peer);

        safeGetUserMedia()
          .then((stream) => {
            if (myVideoRef.current) {
              myVideoRef.current.srcObject = stream;
            }
          })
          .catch((err) => {
            console.error("Initial media setup failed:", err);
            setConnectionStatus("ë¯¸ë””ì–´ ì„¤ì • ì‹¤íŒ¨");
          });
      }
      return () => {
        if (peer) {
          peer.destroy();
        }
      };
    }
  }, [myUniqueId]);

  useEffect(() => {
    const newId = generateUniqueId();
    setMyUniqueId(newId);
    // URLì—ì„œ viewerId ê°€ì ¸ì˜¤ê¸°
    const urlViewerId = getViewerIdFromUrl();
    setViewerId(urlViewerId);
    addDebugLog(`Viewer ID from URL: ${urlViewerId}`);
  }, []);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ íƒ€ì´ë¨¸ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (recordingTimer) {
        clearInterval(recordingTimer);
      }
    };
  }, [recordingTimer]);

  // í„°ì¹˜ ì‹œì‘ ì²˜ë¦¬
  const handleTouchStart = (e: React.TouchEvent | TouchEvent) => {
    if ("touches" in e && e.touches.length === 1) {
      touchStartYRef.current = e.touches[0].clientY;
      isDraggingRef.current = true;
    }
  };

  // í„°ì¹˜ ì´ë™ ì²˜ë¦¬
  const handleTouchMove = (e: React.TouchEvent | TouchEvent) => {
    if (!isDraggingRef.current || touchStartYRef.current === null) return;

    if ("touches" in e) {
      const currentY = e.touches[0].clientY;
      const deltaY = currentY - touchStartYRef.current;

      // ë“œë˜ê·¸ ë°©í–¥: ì•„ë˜ë¡œ ë“œë˜ê·¸í•˜ë©´ ì¤Œì¸(í™•ëŒ€), ìœ„ë¡œ ë“œë˜ê·¸í•˜ë©´ ì¤Œì•„ì›ƒ(ì¶•ì†Œ)
      setZoomLevel((prev) => {
        // ìµœì†Œê°’ì„ 0.5ë¡œ ì„¤ì •í•˜ì—¬ ë” ì¶•ì†Œ ê°€ëŠ¥í•˜ë„ë¡ í•¨
        const newZoom = Math.max(0.5, Math.min(10, prev + deltaY * 0.1));
        updateZoom(newZoom);
        return newZoom;
      });

      touchStartYRef.current = currentY;
    }
  };

  // í„°ì¹˜ ì¢…ë£Œ ì²˜ë¦¬
  const handleTouchEnd = () => {
    touchStartYRef.current = null;
    isDraggingRef.current = false;
  };

  // ì¤Œ ë ˆë²¨ ë³€ê²½ ì‹œ ìº”ë²„ìŠ¤ ì—…ë°ì´íŠ¸ë§Œ í•„ìš” (ìë™ìœ¼ë¡œ ì ìš©ë¨)
  // ê¸°ì¡´ updateZoom í•¨ìˆ˜ëŠ” ë” ì´ìƒ í•„ìš” ì—†ìŒ
  const updateZoom = (newZoomLevel: number) => {
    setZoomLevel(newZoomLevel);
    addDebugLog(`Zoom level set to: ${newZoomLevel}`);
  };

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }

      if (canvasStreamRef.current) {
        canvasStreamRef.current.getTracks().forEach((track) => track.stop());
      }
    };
  }, []);

  // í„°ì¹˜ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
  useEffect(() => {
    const videoElement = myVideoRef.current;
    if (videoElement) {
      videoElement.addEventListener("touchstart", handleTouchStart);
      videoElement.addEventListener("touchmove", handleTouchMove);
      videoElement.addEventListener("touchend", handleTouchEnd);
      videoElement.addEventListener("touchcancel", handleTouchEnd);

      return () => {
        videoElement.removeEventListener("touchstart", handleTouchStart);
        videoElement.removeEventListener("touchmove", handleTouchMove);
        videoElement.removeEventListener("touchend", handleTouchEnd);
        videoElement.removeEventListener("touchcancel", handleTouchEnd);
      };
    }
  }, []);

  return (
    <div className="relative h-[100dvh] w-[100dvw] overflow-hidden">
      {/* ìˆ¨ê²¨ì§„ ìº”ë²„ìŠ¤ */}
      <canvas ref={canvasRef} style={{ display: "none" }} />

      {/* ë¹„ë””ì˜¤ ìš”ì†Œ (ë¯¸ë¦¬ë³´ê¸°ìš©) */}
      <video
        style={{
          width: "100%",
          height: "100%",
          objectFit: "cover",
          touchAction: "none",
          transformOrigin: "center",
        }}
        playsInline
        ref={myVideoRef}
        autoPlay
        muted
        onTouchStart={handleTouchStart as any}
        onTouchMove={handleTouchMove as any}
        onTouchEnd={handleTouchEnd as any}
        onTouchCancel={handleTouchEnd as any}
      />

      {/* í˜„ì¬ ì¤Œ ë ˆë²¨ í‘œì‹œ (ì„ íƒì‚¬í•­) */}
      <div className="absolute top-4 right-4 bg-black bg-opacity-50 text-white px-2 py-1 rounded">
        {Math.round(zoomLevel * 100) / 100}x
      </div>
      <button
        onClick={isStreaming ? handleCut : handleCall}
        disabled={isProcessing}
        className="absolute top-1/2 transform -translate-y-1/2 rotate-90 bg-black text-white px-6 py-4 rounded-xl font-bold text-xl"
      >
        {isStreaming ? "Cut! ğŸ¬" : "Action! ğŸ¬"}
      </button>

      {/* ì¤‘ì•™ ë¡œë”© ì¸ë””ì¼€ì´í„° */}
      {isProcessing && (
        <div className="absolute inset-0 flex items-center justify-center bg-black bg-opacity-50">
          <div className="flex flex-col items-center gap-4">
            <Image
              src="/loading.svg"
              alt="uploading..."
              width={100}
              height={24}
              priority
              className="rotate-90"
            />
          </div>
        </div>
      )}

      {/* ë””ë²„ê¹… ì •ë³´ì™€ ë¡œê·¸ë¥¼ í•¨ê»˜ í‘œì‹œ */}
      <div className="absolute top-4 left-4 bg-black bg-opacity-50 text-white p-2 rounded text-sm max-w-[80%] overflow-hidden">
        <div>ì—°ê²° ìƒíƒœ: {connectionStatus}</div>
        <div>í†µí™” ìƒíƒœ: {callStatus}</div>
        <div>ìŠ¤íŠ¸ë¦¬ë°: {isStreaming ? "ì¼œì§" : "êº¼ì§"}</div>
        <div>ë·°ì–´ ID: {viewerId}</div>
        <div className="h-px bg-white my-2" />
        <div className="text-xs">
          {debugLogs.map((log, index) => (
            <div
              key={index}
              className="whitespace-nowrap overflow-hidden text-ellipsis"
            >
              {log}
            </div>
          ))}
        </div>
      </div>
    </div>
  );
};

export default DollyZoomCamera;
